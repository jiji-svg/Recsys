{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da97766b",
   "metadata": {},
   "source": [
    "### 필수 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f53321-a503-49c4-acbf-f5085329b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U transformers==4.38.2\n",
    "!pip3 install -q -U datasets==2.18.0\n",
    "!pip3 install -q -U bitsandbytes==0.42.0\n",
    "!pip3 install -q -U peft==0.9.0\n",
    "!pip3 install -q -U trl==0.7.11\n",
    "!pip3 install -q -U accelerate==0.27.2\n",
    "!pip3 install -q -U wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb2bdd",
   "metadata": {},
   "source": [
    "### 데이터 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f9b13-0a0b-48d4-a1e0-d83710bc8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000302/data/data.tar.gz\n",
    "# !tar -xvf data.tar.gz\n",
    "# !rm -rf data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4816e",
   "metadata": {},
   "source": [
    "### 허깅페이스 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3a3f1-4c08-4586-a825-17004b24c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd845f",
   "metadata": {},
   "source": [
    "### WandB login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38f5b3",
   "metadata": {},
   "source": [
    "### 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce52c5-5b04-4a77-9420-6613d6c927b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd86c7-3e6e-4d65-91d9-5548c6bb1471",
   "metadata": {},
   "source": [
    "## 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173dd25-e922-4982-8288-abc943827eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\", \n",
    ")\n",
    "# Quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9770b5-5424-4372-a19e-48cbd9cd6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"beomi/OPEN-SOLAR-KO-10.7B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72531a96-fbca-45b0-99b3-4473560b7e90",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0900f-1d38-48f8-ae4a-56fd1376c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "valid_df = pd.read_csv('../data/dev.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f19ee-a4b1-4035-a49f-09a4a48b3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.head())\n",
    "display(valid_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ba815-130e-442f-951f-c9b601cee317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame을 Dataset으로 변환\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "valid_dataset = Dataset.from_pandas(valid_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# DatasetDict 생성\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'valid': valid_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad189f5-1720-4363-8ae0-10703002d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45093f6c-98ac-47c6-975f-bb16b651e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 형태 확인\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb107e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871aa58-8d65-4282-af79-a36178079c77",
   "metadata": {},
   "source": [
    "## 프롬프트 형태로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa21375-f131-448c-9d2d-a56218d41616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(sample):\n",
    "    return f\"\"\"<s>### Instruction:\n",
    "당신은 대화를 요약해주는 유능한 AI입니다. \\\n",
    "당신의 임무는 다음에 나오는 대화를 요약하는 것입니다. \\\n",
    "당신의 대답은 오직 제공된 대화에만 근거해야 합니다.\n",
    "\n",
    "### Dialogue:\n",
    "{sample['dialogue']}\n",
    "\n",
    "### Summary:\n",
    "{sample['summary']}</s>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627a990-3673-4f81-9878-fd1fdc7a24e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_formatter(dataset['train'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3fa6c-b484-4fe1-8c03-afef5e9043a4",
   "metadata": {},
   "source": [
    "## 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf59813",
   "metadata": {},
   "source": [
    "### WandB 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45cf7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    entity='NLP-team3',\n",
    "    project='OPEN-SOLAR-KO-10.7B',\n",
    "    name=f\"OPEN-SOLAR-KO-10.7B-{str(int(time.time()))}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa958945",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82881292",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    logging_steps=4,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=4e-4,  ### 2e-4\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    tf32=True,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_ratio=0.06,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    disable_tqdm=False,\n",
    "    weight_decay=0.01,\n",
    "    report_to='wandb',     # Logging에 wandb를 이용함\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset['valid'],\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    formatting_func=prompt_formatter,\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adab40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e552ee-e033-4109-8bbd-5cb1958922be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb 종료\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAPTER_MODEL = \"lora_adapter\"\n",
    "\n",
    "trainer.model.save_pretrained(ADAPTER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00274209",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"beomi/OPEN-SOLAR-KO-10.7B\"\n",
    "ADAPTER_MODEL = \"lora_adapter\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto', torch_dtype=torch.float16)\n",
    "model = PeftModel.from_pretrained(model, ADAPTER_MODEL, device_map='auto', torch_dtype=torch.float16)\n",
    "\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model.save_pretrained('OPEN-SOLAR-KO-10.7B-sum')\n",
    "tokenizer.save_pretrained('OPEN-SOLAR-KO-10.7B-sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df00567",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_HUB_PATH = 'whybe-choi/OPEN-SOLAR-KO-10.7B-sum' # 여기에 {본인의 허깅페이스 허브}/{저장하고자 하는 이름} 형태로 작성\n",
    "HUGGINGFACE_AUTH_TOKEN = '' # 허깅페이스 write token\n",
    "\n",
    "model.push_to_hub(\n",
    "   MODEL_SAVE_HUB_PATH,\n",
    "   use_temp_dir=True,\n",
    "   use_auth_token=HUGGINGFACE_AUTH_TOKEN\n",
    ")\n",
    "tokenizer.push_to_hub(\n",
    "   MODEL_SAVE_HUB_PATH,\n",
    "   use_temp_dir=True,\n",
    "   use_auth_token=HUGGINGFACE_AUTH_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c1c10",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329344ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda96000",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNE_MODEL = \"whybe-choi/OPEN-SOLAR-KO-10.7B-sum\"\n",
    "\n",
    "finetune_model = AutoModelForCausalLM.from_pretrained(FINETUNE_MODEL, low_cpu_mem_usage=True, quantization_config=bnb_config, device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(FINETUNE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bfbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_finetuned = pipeline(\"text-generation\", model=finetune_model, tokenizer=tokenizer, max_new_tokens=192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f1c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['dialogue'])):\n",
    "        prompt = f\"\"\"<s>### Instruction:\n",
    "당신은 대화를 요약해주는 유능한 AI입니다. \\\n",
    "당신의 임무는 다음에 나오는 대화를 요약하는 것입니다. \\\n",
    "당신의 대답은 오직 제공된 대화에만 근거해야 합니다.\n",
    "\n",
    "### Dialogue:\n",
    "{example['dialogue'][i]}\n",
    "\n",
    "### Summary:\n",
    "\"\"\"\n",
    "        output_texts.append(prompt)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5790a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dataset['test']\n",
    "print(generate_prompt(test_data[:1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afc53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = generate_prompt(test_data[:1])[0]\n",
    "\n",
    "outputs = pipe_finetuned(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    temperature=0.1, \n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.1,\n",
    ")\n",
    "summary = outputs[0][\"generated_text\"][len(prompt):]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d79b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "prompts = generate_prompt(dataset['test'])\n",
    "\n",
    "for idx, prompt in enumerate(tqdm(prompts)):\n",
    "    outputs = pipe_finetuned(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.1,\n",
    "    )\n",
    "    summary = outputs[0][\"generated_text\"][len(prompt):]\n",
    "\n",
    "    if idx % 50 == 0:\n",
    "        print(\"=\"*25, \"[ 대화 ]\", \"=\"*25)\n",
    "        print(dataset['test'][idx][\"dialogue\"])\n",
    "        print(\"=\"*25, \"[ 요약 ]\", \"=\"*25)\n",
    "        print(summary)\n",
    "        print()\n",
    "\n",
    "    submission.loc[idx, 'summary'] = summary.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../submission_solar.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14420527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
